                   *********************************
                   *                               *
                   *  USING CG_DESCENT WITH CUTEst *
                   *                               *
                   *********************************

              ( Last modified on 3 Apr 2014 at 16:00:00 )


WHAT IS CG_DESCENT?
-------------------

The CG_DESCENT package is a nonlinear congugate-gradient
method for large-scale unconstrained minimization designed 
by William Hager and Hongchao Zhang (U. Florida).

HOW DO I GET CG_DESCENT?
------------------------

See

  http://www.math.ufl.edu/~hager/papers/CG/

COMPILING THE OBJECT MODULE FOR CG_DESCENT
------------------------------------------

The CG_DESCENT file cg_descent.c should be compiled, and the resulting 
file cg_descent.o should be placed in either the user-defined directory 
$CG_DESCENT or in $CUTEST/objects/(architecture)/double/ for the architecture
you intend to use.

There is no single-precision version.

USING THE CG_DESCENT INTERFACE TOOL
-----------------------------------

Suppose you wish to solve the problem written in SIF format contained
in the file probname.SIF.

The CG_DESCENT interface tools require two input files:

   probname.SIF    specifies the problem in SIF format
   CG_DESCENT.SPC  sets values for CG_DESCENT run-time parameters

If no CG_DESCENT.SPC file is present in the current directory, the default
version is copied from the $CUTER/src/cg_descent directory. 
This default file is as follows:

1.e-6     grad_tol (relative stopping tolerance--see doc for StopFac)
1         PrintFinal 0 (no print) 1 (print error messages, final error)
0         PrintLevel 0 (no print) 1 (intermediate results)
0         PrintParms 0 (no print) 1 (display parameter values)
0         LBFGS 0 (use LBFGS when memory>=n) 1 (always use LBFGS)
11        memory (number of LBFGS vectors stored in memory)
8         SubCheck (check subspace condition if SubCheck*mem)
4         SubSkip (check subspace condition every Subskip*mem iterations)
0.001     eta0 (enter subspace if subspace dimension = memory and grad<=eta0)
0.900     eta1 (enter subspace if subspace dimension=memory and rel grad<=eta1)
1.e-10    eta2 (enter subspace if rel grad<=eta2)
0         AWolfe 0 (Wolfe -- see AWolfeFac above) 1 (approx Wolfe)
1.e-3     AWolfeFac (AWolfe = 0 => set AWolfe = 1 if |f-f0| < Awolfe_fac*Ck)
0.7       Qdecay (used in Qk update: Qk = Qdecay*Qk + 1)
1000      nslow (terminate if>nslow iterations without strict improvement)
1         StopRule 1 (|grad|_infty<=max(tol,|grad|_0*StopFact) 0 (<=tol*(1+|f|))
0.e-12    StopFac (factor multiplying starting |grad|_infty in StopRule)
1         PertRule (0 => eps, 1 => eps*Ck)
1.e-6     eps  (perturbation parameter for computing fpert)
10.0       egrow (factor by which eps grows when line search fails)
1         QuadStep (use initial quad interpolation in line search)
1.e-12    QuadCutOff (QuadStep if relative change in f > QuadCutOff)
1.e-10    QuadSafe (max factor by which a quad step can reduce the step size)
1         UseCubic 1 (use a cubic step when possible) 
1.e-12    CubicCutOff (use cubic step when |f_k+1 - f_k|/|f_k| > CubicCutOff)
1.e-30    SmallCost (|f| < SmallCost*starting cost => skip QuadStep)
0         debug 0 (no debugging) 1 (check for no increase in f)
1.e-10    debugtol (check that f_k+1 - f_k <= debugtol*C_k when debug=1)
0         step 0 (no initial line search guess) 1 (guess in gnorm)
1000000   maxit (abort cg after maxit iterations)
50        ntries (max # of times the bracketing interval grows during expansion)
200.0     ExpandSafe (max factor secant step increases step in expansion phase)
1.05      SecantAmp (factor by which secant step is amplified during expansion)
2.0       RhoGrow (factor by which rho grows during expansion phase)
5         neps (maximum number of times that eps is updated)
10        nshrink (maximum number of times the bracketing interval shrinks)
50        nline (maximum number of iterations in line search)
6.0       restart_fac (restart cg in restart_fac*n iterations)
0.0       feps (stop when value change <= feps*|f|)
1.3       nan_rho (growth fact when searching for bracketing interval after NaN)
0.1       nan_decay (decay factor for stepsize after NaN)
0.1       delta (Wolfe line search parameter)
0.9       sigma (Wolfe line search parameter)
0.66      gamma (required decay factor in interval)
5.0       rho (interval growth factor used to get bracketing interval)
0.01      psi0  (factor used in starting guess for iteration 1)
0.1       psi_lo (evaluate in [psi_lo, psi_hi]*psi2*previous step 
10.0      psi_hi  during QuadStep))
1.0       psi1 (factor previous step multiplied by in QuadStep)
2.0       psi2 (factor previous step is multipled by for startup)
0         AdaptiveBeta (T => choose beta adaptively, F => use theta)
0.4       BetaLower (lower bound factor for beta)
1.0       theta (parameter describing the cg_descent family)
1.e-12    qeps (parameter in cost error for quadratic restart criterion)
1.e-8     qrule (parameter used to decide if cost is quadratic)
6         qrestart (# of its the function should be ~ quadratic before restart)

The reader is referred to the paper quoted below and the code itself if he or 
she wishes to modify these parameters.

To run with CUTEst, use the runcutest command with the -p cg_descent option.
See the man page for runcutest for more details of other options.

REFERENCE
---------

 W. W. Hager and H. Zhang, 
 "Algorithm 851: CG_DESCENT, A conjugate gradient method with guaranteed 
 descent", ACM Transactions on Mathematical Software, 32 (2006), 113-137. 

